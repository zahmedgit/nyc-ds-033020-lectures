{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Selection\n",
    "\n",
    "Feature selection is the process of selecting a subset of relevant features for use in model construction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Top reasons to use feature selection are:\n",
    "* It enables the machine learning algorithm to train faster.\n",
    "* It reduces the complexity of a model and makes it easier to interpret.\n",
    "* It improves the accuracy of a model if the right subset is chosen.\n",
    "* It reduces overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Import the packages we will use for this notebook***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 300)\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Set up or initial dataframe by removing variable and transforming others.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original  = pd.read_csv('resources/cleaned_movie_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = original.drop(columns=['color', 'director_name','actor_2_name','language', 'country',\n",
    "                 'movie_imdb_link', 'movie_title', 'num_voted_users', \n",
    "                 'movie_facebook_likes','actor_1_name', 'actor_3_name',\n",
    "                 'content_rating', 'rating', 'genres'], \n",
    "                 axis =1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_old'] =  df['title_year'].map(lambda x: 2016-x )\n",
    "df = df[df['yr_old']<20]\n",
    "df = df[df['budget']<300000000]\n",
    "df = df[(df['gross']>1000000) & (df['gross']<500000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols  = ['duration','director_facebook_likes', 'actor_3_facebook_likes', \n",
    "       'actor_1_facebook_likes', 'gross', 'cast_total_facebook_likes',\n",
    "       'facenumber_in_poster', 'budget'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break the colums in to groups to plot 4 on a row at a time\n",
    "n = 4\n",
    "row_groups= [cols[i:i+n] for i in range(0, len(cols), n) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in row_groups:\n",
    "    pp = sns.pairplot(data=df, y_vars=['gross_sqrt'],x_vars=i, kind=\"reg\", height=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['num_critic_for_reviews', 'duration', 'director_facebook_likes',\n",
    "       'actor_3_facebook_likes', 'actor_1_facebook_likes',\n",
    "       'cast_total_facebook_likes', 'facenumber_in_poster',\n",
    "       'num_user_for_reviews', 'budget', 'title_year',\n",
    "       'actor_2_facebook_likes', 'imdb_score', 'G', 'PG', 'PG-13',\n",
    "       'R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['gross']\n",
    "features = df[feature_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features.fillna(features.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=22,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take the log of the target data to create a better linear relationship**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.log(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale all of my features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train =pd.DataFrame(data=scaler.transform(X_train), columns=feature_columns)\n",
    "X_test =pd.DataFrame(data=scaler.transform(X_test), columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm = lm.fit(X_train, y_log)\n",
    "\n",
    "y_train_pred = lm.predict(X_train)\n",
    "\n",
    "#exponentiate the predictions to get them on the same original scale \n",
    "y_train_pred = np.exp(y_train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , train_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the MAE to see if it is off too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "y_pred = np.exp(y_pred)\n",
    "\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "\n",
    "\n",
    "print('Training: ', int(train_rmse), \"vs. Testing: \", int(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Plot the residuals after fitting a linear model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.residplot( y_train, y_train_pred,lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot( y_test, y_pred,lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred, columns=['gross_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([pd.DataFrame(y_pred, columns=['gross_pred']), X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.sort_values(by='gross_pred', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original.sort_values(by=['director_facebook_likes','actor_3_facebook_likes'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on this residual plot how might we want to transform our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Types of Feature Selection\n",
    "\n",
    "* Filter Methods\n",
    "* Wrapper Methods\n",
    "* Embedded Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Filter Methods\n",
    "Filter feature selection methods apply a statistical measure to assign a scoring to each feature. The features are ranked by the score and either selected to be kept or removed from the dataset. The methods are often univariate and consider the feature independently, or with regard to the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./resources/Filter_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Examples:** \n",
    "* F-Test\n",
    "* Chi squared test \n",
    "* Information gain \n",
    "* Correlation coefficient scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./resources/FS1.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Variables based on correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = X_train.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = X_train.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index of feature columns with correlation greater than 0.90\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "X_train.drop(columns=to_drop, inplace=True)\n",
    "X_test.drop(columns=to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Inflation Factor (VIF) \n",
    "\n",
    "VIFis a measure of colinearity among predictor variables within a multiple regression. The variance inflation factor for the estimated regression coefficient $b_j$ — denoted $VIF_j$ —is just the factor by which the variance of $b_j$ is \"inflated\" by the existence of correlation among the predictor variables in the model.In particular, the variance inflation factor for the jth predictor is:\n",
    "\n",
    "$$VIF_j=\\frac{1}{1-R_{j}^{2}}$$\n",
    "\n",
    "\n",
    "where $R^2_j$  is the $R^2$-value obtained by regressing the jth predictor on the remaining predictors. \n",
    "\n",
    "\n",
    "Inspect the factors for each predictor variable, if the VIF is between 5-10, multicolinearity is likely present and you should consider dropping the variable.\n",
    "\n",
    "https://online.stat.psu.edu/stat462/node/180/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif[\"features\"] = X_train.columns\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.corrwith(y_train).abs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  F Test\n",
    "\n",
    "F Test is a statistical test used to compare between models and check if the difference is significant between the model.\n",
    "\n",
    "F-Test does a hypothesis testing model X and Y where X is a model created by just a constant and Y is the model created by a constant and a feature.\n",
    "\n",
    "The least square errors in both the models are compared and checks if the difference in errors between model X and Y are significant or introduced by chance.\n",
    "\n",
    "F-Test is useful in feature selection as we get to know the significance of each feature in improving the model.\n",
    "\n",
    "Scikit learn provides the Selecting K best features using F-Test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I am using the F-test to select the 10 top varaibles for this model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = X_train.columns[selector.get_support()]\n",
    "removed_columns = X_train.columns[~selector.get_support()]\n",
    "# X_train = X_train[selected_columns]\n",
    "# X_test = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(removed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_kbest = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_kbest = lm_kbest.fit(X_train[selected_columns], y_train)\n",
    "\n",
    "y_train_kbest = lm_kbest.predict(X_train[selected_columns])\n",
    "\n",
    "\n",
    "trainK_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_kbest))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , trainK_rmse)\n",
    "\n",
    "y_kbest = lm_kbest.predict(X_test[selected_columns])\n",
    "\n",
    "testK_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_kbest))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , testK_rmse)\n",
    "\n",
    "\n",
    "print('Original: ', test_rmse, \"vs. KBest: \", testK_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrapper Methods\n",
    "\n",
    "Wrapper methods consider the selection of a set of features as a search problem, where different combinations are prepared, evaluated and compared to other combinations. A predictive model is used to evaluate a combination of features and assign a score based on model accuracy.\n",
    "\n",
    "The search process may be methodical such as a best-first search, it may stochastic such as a random hill-climbing algorithm, or it may use heuristics, like forward and backward passes to add and remove features.\n",
    "\n",
    "Wrapper Methods promises you a best set of features with a extensive greedy search.\n",
    "\n",
    "But the main drawbacks of wrapper methods is the sheer amount of models that needs to be trained. It is computationally very expensive and is infeasible with large number of features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./resources/Wrapper_1.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "\n",
    "An example if a wrapper method is the recursive feature elimination algorithm.\n",
    "\n",
    "As the name suggests, this method eliminates worst performing features on a particular model one after the other until the best subset of features are known.\n",
    "\n",
    "\n",
    "Recursive elimination eliminates the least explaining features one after the other.\n",
    "For data with n features,\n",
    "\n",
    "- On first round ‘n-1’ models are created with combination of all features except one. The least performing feature is removed\n",
    "\n",
    "- On second round ‘n-2’ models are created by removing another feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./resources/rfe_graph.png' width=500/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recursive feature eliminator that scores features by mean squared errors\n",
    "selector = RFECV(estimator=ols, step=1, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit recursive feature eliminator \n",
    "selector.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rfe = X_train.columns[selector.support_]\n",
    "removed_rfe = X_train.columns[~selector.support_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(removed_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(selected_rfe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_rfe = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_rfe = lm_rfe.fit(X_train[selected_rfe], y_train)\n",
    "\n",
    "y_rfe = lm_rfe.predict(X_train[selected_rfe])\n",
    "\n",
    "\n",
    "trainRFE_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_rfe))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , trainRFE_rmse)\n",
    "\n",
    "y_pred_rfe = lm_rfe.predict(X_test[selected_rfe])\n",
    "\n",
    "testRFE_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred_rfe))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , testRFE_rmse)\n",
    "\n",
    "\n",
    "print('Original: ', test_rmse, \"vs. KBest: \", testK_rmse, \"vs. RFE: \", testRFE_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Embedded Methods\n",
    "\n",
    "Embedded methods learn which features best contribute to the accuracy of the model while the model is being created. The most common type of embedded feature selection methods are regularization methods.\n",
    "\n",
    "Regularization methods are also called penalization methods that introduce additional constraints into the optimization of a predictive algorithm (such as a regression algorithm) that bias the model toward lower complexity (fewer coefficients).\n",
    "\n",
    "Examples of regularization algorithms are the LASSO, Elastic Net and Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./resources/Embedded_1.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Plot to compare the size of all of our coefficients***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(data=lm.coef_ ).T\n",
    "coef.columns = feature_columns\n",
    "\n",
    "model_coef = coef.T.sort_values(by=0).T\n",
    "model_coef.plot(kind='bar', title='Modal Coefficients', legend=False, figsize=(16,8),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training the model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.01, normalize=False)\n",
    "\n",
    "lasso.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "train_rmse = metrics.mean_absolute_error(y_train, y_train_pred)\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Training Error: '+ str(train_rmse) )\n",
    "print('Testing Error: '+ str(test_rmse) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef01 = pd.DataFrame(data=lasso.coef_).T\n",
    "lasso_coef01.columns = X_train.columns\n",
    "lasso_coef01 = lasso_coef01.T.sort_values(by=0).T\n",
    "lasso_coef01.plot(kind='bar', title='Modal Coefficients', legend=False, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef01.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training the model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso1 = Lasso(alpha=.1, normalize=False)\n",
    "\n",
    "lasso1.fit(X_train,y_train)\n",
    "\n",
    "y_train_lasso1 = lasso1.predict(X_train)\n",
    "y_pred_lasso1 = lasso1.predict(X_test)\n",
    "\n",
    "train_rmse_lasso1 = metrics.mean_absolute_error(y_train, y_train_lasso1)\n",
    "test_rmse_lasso1 = np.sqrt(metrics.mean_squared_error(y_test, y_pred_lasso1))\n",
    "print('Training Error: '+ str(train_rmse_lasso1) )\n",
    "print('Testing Error: '+ str(test_rmse_lasso1) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef1 = pd.DataFrame(data=lasso1.coef_).T\n",
    "lasso_coef1.columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coef1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lasso_coef1 = lasso_coef1.T.sort_values(by=0).T\n",
    "lasso_coef1.plot(kind='bar', title='Modal Coefficients', legend=False, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: when do we use which method?\n",
    "\n",
    "Lasso probably appears to be the easiest method to use to select the features of your model. So why would you bother with any of the other methods?  \n",
    "\n",
    "A Lasso algorithm is only for linear models, and you might rather use a different machine learning algorithm like K-Nearest Neighbors. Therefore, a filter or wrapper method could be used to perform your feature selection.\n",
    "\n",
    "You might start off with hundreds or thousands of features that you want to select from. This could take a while to run a wrapper or embedded method, so you can use a filter method first to reduce your model size and have it run more quickly.  \n",
    "\n",
    "Finally you can also combine these methods together. So you might start with a filter method to remove some of the features that are obviously non-impactful to our target variable, then run a wrapper or embedded method to finish the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('resources/cleaned_movie_data.csv', index_col=0)\n",
    "\n",
    "movies_df.drop(columns=['color', 'director_name','actor_2_name','language', 'country',\n",
    "                 'movie_imdb_link', 'movie_title', 'num_voted_users', \n",
    "                 'movie_facebook_likes','actor_1_name', 'actor_3_name',\n",
    "                 'content_rating', 'rating', 'genres'], \n",
    "                 axis =1, inplace=True)\n",
    "\n",
    "movies_df['yr_old'] =  movies_df['title_year'].map(lambda x: 2016-x )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4157, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df[(movies_df['yr_old']<21) & \n",
    "                      (movies_df['gross']>1000000) & (movies_df['gross']<500000000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3029, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['num_critic_for_reviews', 'duration', 'director_facebook_likes',\n",
    "       'actor_3_facebook_likes', 'actor_1_facebook_likes',\n",
    "       'cast_total_facebook_likes', 'facenumber_in_poster',\n",
    "       'num_user_for_reviews', 'budget', 'title_year',\n",
    "       'actor_2_facebook_likes', 'imdb_score', 'G', 'PG', 'PG-13',\n",
    "       'R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = movies_df['gross']\n",
    "features = movies_df[feature_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features.fillna(features.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=22,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>34964818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>50129186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>102515793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>37752931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360</th>\n",
       "      <td>5709616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>13208023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>130468626.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>234903076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>64685359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>7443007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>5694401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>3193102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>150832203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>10561238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>115603980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>9437933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>350034110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>30920167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>77413017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>84136909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>21244913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>42272747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>49024969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>40076438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>15294553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>1943649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>60655503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>32741596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>137850096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>1641788.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>3105269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>14131298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>14637490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>14891000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>80033643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>6851636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>18642318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>80050171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>4306697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>8044906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>117559438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>95308367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>30993544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>24520892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344</th>\n",
       "      <td>4018695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>177575142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>58328680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>57262492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>24343673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>34746109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>4992159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>3122616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>120776832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>3442820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>63536011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>61355436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852</th>\n",
       "      <td>12006514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>70327868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>3247816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>4105123.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2423 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gross\n",
       "3879   34964818.0\n",
       "1383   50129186.0\n",
       "364   102515793.0\n",
       "1252   37752931.0\n",
       "4360    5709616.0\n",
       "1303   13208023.0\n",
       "57    130468626.0\n",
       "4778  234903076.0\n",
       "380    64685359.0\n",
       "1757    7443007.0\n",
       "2452    5694401.0\n",
       "3192    3193102.0\n",
       "413   150832203.0\n",
       "3162   10561238.0\n",
       "663   115603980.0\n",
       "4931    9437933.0\n",
       "45    350034110.0\n",
       "1809   30920167.0\n",
       "4024   77413017.0\n",
       "1902   84136909.0\n",
       "4054   21244913.0\n",
       "595    42272747.0\n",
       "2127   49024969.0\n",
       "784    40076438.0\n",
       "2973   15294553.0\n",
       "4383    1943649.0\n",
       "105    60655503.0\n",
       "997    32741596.0\n",
       "61    137850096.0\n",
       "3203    1641788.0\n",
       "...           ...\n",
       "4108    3105269.0\n",
       "1016   14131298.0\n",
       "3915   14637490.0\n",
       "3488   14891000.0\n",
       "739    80033643.0\n",
       "3612    6851636.0\n",
       "3486   18642318.0\n",
       "1319   80050171.0\n",
       "3771    4306697.0\n",
       "4729    8044906.0\n",
       "1526  117559438.0\n",
       "1043   95308367.0\n",
       "1270   30993544.0\n",
       "1149   24520892.0\n",
       "3344    4018695.0\n",
       "842   177575142.0\n",
       "1840   58328680.0\n",
       "2024   57262492.0\n",
       "1113   24343673.0\n",
       "3367   34746109.0\n",
       "3358    4992159.0\n",
       "4560    3122616.0\n",
       "530   120776832.0\n",
       "3398    3442820.0\n",
       "1618   63536011.0\n",
       "381    61355436.0\n",
       "4852   12006514.0\n",
       "901    70327868.0\n",
       "2725    3247816.0\n",
       "4523    4105123.0\n",
       "\n",
       "[2423 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train, columns=['gross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.concat([pd.DataFrame(X_train, columns=feature_columns), pd.DataFrame(y_train, columns=['gross'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_features = pd.DataFrame(X_test, columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_target = pd.DataFrame(y_test, columns=['gross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.to_csv('movies_training.csv')\n",
    "holdout_features.to_csv('movies_holdout_features.csv')\n",
    "holdout_target.to_csv('movies_holdout_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
