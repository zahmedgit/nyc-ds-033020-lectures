{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp API - Lab\n",
    "\n",
    "\n",
    "\n",
    "## Introduction \n",
    "\n",
    "Now that we've seen how the Yelp API works, it's time to put those API and Pandas skills to work in order to do some basic business analysis! Taking things a step further, you'll also independently explore how to perform pagination in order to retrieve a full results set from the Yelp API!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Create HTTP requests to get data from Yelp API\n",
    "* Parse HTTP responses and save the information in a csv\n",
    "* Perform pagination to retrieve troves of data!\n",
    "* Write Pandas code to answer questions about your data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Introduction\n",
    "\n",
    "For this lab you will analyze the yelp data for a group of businesses to learn more about an industry. You will choose a type of business (Italian Restuarants, Nail Salons, Crossfit gyms) and a location to analyze. Then you will get data from the Yelp API, store that data in a SQL Database on AWS, and write queries to answer questions about the data. \n",
    "\n",
    "\n",
    "### Process:\n",
    "\n",
    "1. Read through the data questions and the API documentation to determine which pieces of information you need to pull from the Yelp API.\n",
    "\n",
    "2. Plan out what . One for the businesses and one for the reviews.\n",
    "\n",
    "3. Create code to:\n",
    "  - Perform a search of businesses using pagination\n",
    "  - Parse the API response for specific data points\n",
    "  - Save the data you pull as a csv\n",
    "\n",
    "4. Use the functions above in a loop that will paginate over the results to retrieve all of the results. \n",
    "\n",
    "5. Create functions to:\n",
    "  - Retrieve the reviews data of one business\n",
    "  - Parse the reviews response for specific review data\n",
    "  - Save the data you pull as a csv\n",
    "\n",
    "6. Take all of the business IDs from your business search, and  using the 3 Python functions you've created, run your business IDs through a loop to get the reviews for each business and save them in a csv.\n",
    "\n",
    "7. Write Pandas code to answer the following questions about your data.\n",
    "\n",
    "\n",
    "Bonus Steps:  \n",
    "- Place your helper functions in a package so that your final notebook only has the major steps listed.\n",
    "- Rewrite your business search functions to be able take an argument for the type of business you are searching for.\n",
    "- Add another group of businesses to your files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Data Questions:\n",
    "\n",
    "- Which are the 5 most reviewed businesses?\n",
    "- What is the highest rating recieved in your data set and how many businesses have that rating?\n",
    "- What percentage of businesses have a rating greater than or  4.5?\n",
    "- What percentage of businesses have a rating less than 3?\n",
    "- What is the average rating of restaurants that have a price label of one dollar sign? Two dollar signs? Three dollar signs? \n",
    "- Return the text of the reviews for the most reviewed restaurant. \n",
    "- Return the name of the business with the most recent review. \n",
    "- Find the highest rated business and return text of the most recent review. If multiple business have the same rating, select the restaurant with the most reviews. \n",
    "- Find the lowest rated business and return text of the most recent review.  If multiple business have the same rating, select the restaurant with the least reviews. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Understanding your data and question\n",
    "\n",
    "Lok at the question and determine what data you will need to store in your database in order to answer the questions. Start to think about what tables will you want to create and what columns will you ahve for those tables. \n",
    "\n",
    "Look at the API documentation, and determine what fields of the API response you will match up with the columns you want in your Pandas Dataframes. \n",
    "\n",
    "\n",
    "https://www.yelp.com/developers/documentation/v3/get_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Create ETL pipeline for the business data from the API\n",
    "\n",
    "Now that you know what data you need from the API, you want to write code that will execute a api call, parse those results and then insert the results into the DB.  \n",
    "\n",
    "It is helpful to break this up into three different functions (*api call, parse results, and insert into DB*) and then you can write a function/script that pull the other three functions together. \n",
    "\n",
    "Let's first do this for the Business endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to make a call to the yelp API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yelp_call(url_params, api_key):\n",
    "    # your code to make the yelp call\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to parse the API response \n",
    "# so that you can easily insert the data in to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(results):\n",
    "    # your code to parse the result to make them easier to insert into the DB\n",
    "    return parsed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to take your parsed data and insert it into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_save(parsed_results, csv_filename):\n",
    "    # your code to save the current results with all of the other results. \n",
    "    # I would save the data every time you pull 50 results\n",
    "    # in case something breaks in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a script that combines the three functions above into a single process.\n",
    "\n",
    "# create a variable  to keep track of which result you are in. \n",
    "cur = 0\n",
    "\n",
    "#set up a while loop to go through and grab the result \n",
    "while cur < num and cur < 1000:\n",
    "    #set the offset parameter to be where you currently are in the results \n",
    "    url_params['offset'] = cur\n",
    "    #make your API call with the new offset number\n",
    "    results = yelp_call(url_params, api_key)\n",
    "    \n",
    "    #after you get your results you can now use your function to parse those results\n",
    "    parsed_results = parse_results(results)\n",
    "    \n",
    "    # use your function to insert your parsed results into the db\n",
    "    data_save(parsed_results, csv_file)\n",
    "    #increment the counter by 50 to move on to the next results\n",
    "    cur += 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 -  Create ETL pipeline for the restaurant review data from the API\n",
    "\n",
    "You've done this for the Businesses, now you need to do this for reviews. You will follow the same process, but your functions will be specific to reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write Pandas code to pull back all of the business ids \n",
    "# you will need these ids to pull back the reviews for each restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that takes a business id \n",
    "# and makes a call to the API for reivews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to parse out the relevant information from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to insert the parsed data into the reviews table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the functions above into a single script  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 -  Write Pandas code that will answer the questions posed. \n",
    "\n",
    "Now that your data is saved in CSVs, you can answer the questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Reference help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pagination\n",
    "\n",
    "Returning to the Yelp API, the [documentation](https://www.yelp.com/developers/documentation/v3/business_search) also provides us details regarding the API limits. These often include details about the number of requests a user is allowed to make within a specified time limit and the maximum number of results to be returned. In this case, we are told that any request has a maximum of 50 results per request and defaults to 20. Furthermore, any search will be limited to a total of 1000 results. To retrieve all 1000 of these results, we would have to page through the results piece by piece, retriving 50 at a time. Processes such as these are often refered to as pagination.\n",
    "\n",
    "Now that you have an initial response, you can examine the contents of the json container. For example, you might start with ```response.json().keys()```. Here, you'll see a key for `'total'`, which tells you the full number of matching results given your query parameters. Write a loop (or ideally a function) which then makes successive API calls using the offset parameter to retrieve all of the results (or 5000 for a particularly large result set) for the original query. As you do this, be mindful of how you store the data. \n",
    "\n",
    "**Note: be mindful of the API rate limits. You can only make 5000 requests per day, and APIs can make requests too fast. Start prototyping small before running a loop that could be faulty. You can also use time.sleep(n) to add delays. For more details see https://www.yelp.com/developers/documentation/v3/rate_limiting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Below is sample code that you can use to help you deal with the pagination parameter and bring all of the functions together.***\n",
    "\n",
    "\n",
    "***Also, something might cause your code to break while it is running. You don't want to constantly repull the same data when this happens, so you should insert the data into the database as you call and parse it, not after you have all of the data***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable  to keep track of which result you are in. \n",
    "cur = 0\n",
    "\n",
    "#set up a while loop to go through and grab the result \n",
    "while cur < num and cur < 1000:\n",
    "    #set the offset parameter to be where you currently are in the results \n",
    "    url_params['offset'] = cur\n",
    "    #make your API call with the new offset number\n",
    "    results = yelp_call(url_params, api_key)\n",
    "    \n",
    "    #after you get your results you can now use your function to parse those results\n",
    "    parsed_results = parse_results(results)\n",
    "    \n",
    "    # use your function to insert your parsed results into the db\n",
    "    data_save(parsed_results)\n",
    "    #increment the counter by 50 to move on to the next results\n",
    "    cur += 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
